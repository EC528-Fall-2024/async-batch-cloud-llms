{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TurboBatch User Dashboard**\n",
    "\n",
    "### **Environment Set-up**\n",
    "Before submitting your job please ensure you have created a new Google Cloud Project with an associated billing account and have the gcloud CLI working in your environment. Additionally, this dashboard requires certain packages be installed. Please make sure to `pip install -r requirements.txt` in your environment before continuing.\n",
    "\n",
    "The scripts below will assist with any further steps:\n",
    "\n",
    "**Ensure our system's service account has all required permissions to your project**\n",
    "\n",
    "To do this, you can simply run our privileges.sh bash script in the terminal. Before running the command, make sure to first navigate to the helpers directory. Please type the following command, replacing [project-id] with your actual project's ID. Simple select 'yes' when prompted and complete the authorization process on the browser.\n",
    "\n",
    "```./privileges.sh [project-id]```\n",
    "\n",
    "### **Upload Input DataFrame into BigQuery Table**\n",
    "\n",
    "Our system requires an input in the form of a BigQuery Table and writes to an output table in the same form. To streamline the process of the creation of these tables, simply run the cell below after changing the variables to upload and create an input table along with creating an empty output table in your project.\n",
    "\n",
    "Please note that the input table must be formated with two columns: `row` (integers) and `prompt_and_text` (strings). See `example.csv` for reference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 GET https://bigquery.googleapis.com/bigquery/v2/projects/sampleproject-440900/datasets/test?prettyPrint=false: Access Denied: Dataset sampleproject-440900:test: Permission bigquery.datasets.get denied on dataset sampleproject-440900:test (or it may not exist).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m input_table_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m output_table_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mCSV_to_BigQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_CSV_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_table_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_table_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\serse\\Desktop\\async-batch-cloud-llms\\User-Script\\helpers\\df.py:52\u001b[0m, in \u001b[0;36mCSV_to_BigQuery\u001b[1;34m(CSV_path, project_id, dataset_id, table_id, output_table_id)\u001b[0m\n\u001b[0;32m     50\u001b[0m dataset\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUS\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Set location as needed\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[1;32m---> 52\u001b[0m     \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_ref\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mNotFound: \n",
      "File \u001b[1;32mc:\\Users\\serse\\Desktop\\async-batch-cloud-llms\\testing\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:874\u001b[0m, in \u001b[0;36mClient.get_dataset\u001b[1;34m(self, dataset_ref, retry, timeout)\u001b[0m\n\u001b[0;32m    872\u001b[0m path \u001b[38;5;241m=\u001b[39m dataset_ref\u001b[38;5;241m.\u001b[39mpath\n\u001b[0;32m    873\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[1;32m--> 874\u001b[0m api_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBigQuery.getDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39mfrom_api_repr(api_response)\n",
      "File \u001b[1;32mc:\\Users\\serse\\Desktop\\async-batch-cloud-llms\\testing\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:837\u001b[0m, in \u001b[0;36mClient._call_api\u001b[1;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[0;32m    835\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[0;32m    836\u001b[0m     ):\n\u001b[1;32m--> 837\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[1;32mc:\\Users\\serse\\Desktop\\async-batch-cloud-llms\\testing\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\serse\\Desktop\\async-batch-cloud-llms\\testing\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32mc:\\Users\\serse\\Desktop\\async-batch-cloud-llms\\testing\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32mc:\\Users\\serse\\Desktop\\async-batch-cloud-llms\\testing\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32mc:\\Users\\serse\\Desktop\\async-batch-cloud-llms\\testing\\Lib\\site-packages\\google\\cloud\\_http\\__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[1;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[0;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 GET https://bigquery.googleapis.com/bigquery/v2/projects/sampleproject-440900/datasets/test?prettyPrint=false: Access Denied: Dataset sampleproject-440900:test: Permission bigquery.datasets.get denied on dataset sampleproject-440900:test (or it may not exist)."
     ]
    }
   ],
   "source": [
    "from helpers.df import CSV_to_BigQuery\n",
    "\n",
    "#TODO Change the below variables before running this cell\n",
    "input_CSV_path = \"example.csv\"\n",
    "project_id = \"sampleproject-440900\"\n",
    "dataset_id = \"test\"\n",
    "input_table_id = \"input\"\n",
    "output_table_id = \"output\"\n",
    "\n",
    "CSV_to_BigQuery(input_CSV_path, project_id, dataset_id, input_table_id, output_table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Submit Job**\n",
    "\n",
    "Fill in the relevant information below and then run the cell to submit a job. Upon submitting a job, there will be an update every three seconds on the status of your job until completion.\n",
    "\n",
    "Note:\n",
    "- Currently supported model: \"gpt-3.5-turbo\"\n",
    "- Leaving API_key empty (\"\") will result in \"sample_response\" being returned for all input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e5e766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 10:28:48,295 - INFO - 🔑 Retrieving API key...\n",
      "2024-12-05 10:28:48,396 - INFO - API key retrieved successfully: 7b57da27-c470-434d-87a6-5f3320a0f410\n",
      "2024-12-05 10:28:48,396 - INFO - 📋 Preparing job data...\n",
      "2024-12-05 10:28:48,396 - INFO - 📤 Submitting job...\n",
      "2024-12-05 10:28:48,559 - INFO - Job submitted successfully.\n",
      "2024-12-05 10:28:48,569 - INFO - ⏳ Monitoring job status...\n",
      "2024-12-05 10:28:48,570 - INFO - 🔎 Checking for Job Status...\n",
      "2024-12-05 10:28:48,754 - ERROR - Failed to retrieve job status: 500, {\"details\":\"'NoneType' object has no attribute 'get'\",\"error\":\"Failed to retrieve job status\"}\n",
      "\n",
      "2024-12-05 10:28:48,754 - ERROR - ❌ Could not retrieve job status. Retrying...\n",
      "2024-12-05 10:28:51,758 - INFO - 🔎 Checking for Job Status...\n",
      "2024-12-05 10:28:51,880 - ERROR - Failed to retrieve job status: 500, {\"details\":\"'NoneType' object has no attribute 'get'\",\"error\":\"Failed to retrieve job status\"}\n",
      "\n",
      "2024-12-05 10:28:51,881 - ERROR - ❌ Could not retrieve job status. Retrying...\n",
      "2024-12-05 10:28:54,882 - INFO - 🔎 Checking for Job Status...\n",
      "2024-12-05 10:28:55,039 - ERROR - Failed to retrieve job status: 500, {\"details\":\"'NoneType' object has no attribute 'get'\",\"error\":\"Failed to retrieve job status\"}\n",
      "\n",
      "2024-12-05 10:28:55,040 - ERROR - ❌ Could not retrieve job status. Retrying...\n",
      "2024-12-05 10:28:58,042 - INFO - 🔎 Checking for Job Status...\n",
      "2024-12-05 10:28:58,187 - ERROR - Failed to retrieve job status: 500, {\"details\":\"'NoneType' object has no attribute 'get'\",\"error\":\"Failed to retrieve job status\"}\n",
      "\n",
      "2024-12-05 10:28:58,187 - ERROR - ❌ Could not retrieve job status. Retrying...\n",
      "2024-12-05 10:29:01,190 - INFO - 🔎 Checking for Job Status...\n",
      "2024-12-05 10:29:01,337 - ERROR - Failed to retrieve job status: 500, {\"details\":\"'NoneType' object has no attribute 'get'\",\"error\":\"Failed to retrieve job status\"}\n",
      "\n",
      "2024-12-05 10:29:01,345 - ERROR - ❌ Could not retrieve job status. Retrying...\n",
      "2024-12-05 10:29:04,348 - INFO - 🔎 Checking for Job Status...\n",
      "2024-12-05 10:29:04,483 - ERROR - Failed to retrieve job status: 500, {\"details\":\"'NoneType' object has no attribute 'get'\",\"error\":\"Failed to retrieve job status\"}\n",
      "\n",
      "2024-12-05 10:29:04,486 - ERROR - ❌ Could not retrieve job status. Retrying...\n",
      "2024-12-05 10:29:07,490 - INFO - 🔎 Checking for Job Status...\n",
      "2024-12-05 10:29:07,621 - INFO - Job 27173a7e-0abb-487a-b5ed-2a9eafc3e823 is complete. Processed 3 rows.\n",
      "2024-12-05 10:29:07,623 - INFO - ✅ Job processing is complete.\n",
      "2024-12-05 10:29:07,623 - INFO - 📊 Final Job Status Retrieved:\n",
      "2024-12-05 10:29:07,624 - INFO - {\n",
      "    \"Client_ID\": \"test\",\n",
      "    \"Job_ID\": \"27173a7e-0abb-487a-b5ed-2a9eafc3e823\",\n",
      "    \"current_row\": 3,\n",
      "    \"total_rows\": 3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from helpers.jobSubmit import submitjob\n",
    "\n",
    "#TODO Change the below variables before running this cell\n",
    "username = \"test_user\"\n",
    "password = \"test_password\"\n",
    "Client_ID = \"test\"\n",
    "User_Project_ID = \"sampleproject-440900\"\n",
    "User_Dataset_ID = \"test\"\n",
    "Input_Table_ID = \"input\"\n",
    "Output_Table_ID = \"output\"\n",
    "Model = \"gpt-3.5-turbo\"\n",
    "API_key = \"\"\n",
    "\n",
    "job, key = submitjob(username, password, Client_ID, User_Project_ID, User_Dataset_ID, Input_Table_ID, Output_Table_ID, Model, API_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Manually Check Job Status by Running Cell Below**\n",
    "\n",
    "If you would like to check on your job status please run the cell below to do so. Note that this can only be run after the previous cell has been run. Make sure to wait a few seconds before trying to obtain the status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 10:29:16,250 - INFO - 🔎 Checking for Job Status...\n",
      "2024-12-05 10:29:16,370 - INFO - Job 27173a7e-0abb-487a-b5ed-2a9eafc3e823 is complete. Processed 3 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'complete',\n",
       " 'details': {'Client_ID': 'test',\n",
       "  'Job_ID': '27173a7e-0abb-487a-b5ed-2a9eafc3e823',\n",
       "  'current_row': 3,\n",
       "  'total_rows': 3}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers.jobStatus import check_job_status\n",
    "\n",
    "check_job_status(job, Client_ID, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save Output BigQuery Table as a CSV**\n",
    "\n",
    "If you prefer to have the output responses and corresponding rows saved in your local machine as a CSV rather than checking the BigQuery table in your project, run the cell below to access the output table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.df import BigQuery_to_CSV\n",
    "\n",
    "#TODO Change the below variables before running this cell\n",
    "project_id = \"sampleproject-440900\"\n",
    "dataset_id = \"test\"\n",
    "output_table_id = \"output\"\n",
    "output_csv_path = \"output.csv\"\n",
    "\n",
    "BigQuery_to_CSV(project_id, dataset_id, output_table_id, output_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
