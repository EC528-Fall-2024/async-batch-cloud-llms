{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TurboBatch User Dashboard**\n",
    "\n",
    "### **Environment Set-up**\n",
    "Before submitting your job please ensure you have created a new Google Cloud Project with an associated billing account and have the gcloud CLI working in your environment. Additionally, this dashboard requires certain packages be installed. Please make sure to `pip install -r requirements.txt` in your environment before continuing.\n",
    "\n",
    "The scripts below will assist with any further steps:\n",
    "\n",
    "**Ensure our system's service account has all required permissions to your project**\n",
    "\n",
    "To do this, you can simply run our privileges.sh bash script in the terminal. Please type the following command, replacing [project-id] with your actual project's ID. Simple select 'yes' when prompted and complete the authorization process on the browser.\n",
    "\n",
    "```./privileges.sh [project-id]```\n",
    "\n",
    "### **Upload Input DataFrame into BigQuery Table**\n",
    "\n",
    "Our system requires an input in the form of a BigQuery Table and writes to an output table in the same form. To streamline the process of the creation of these tables, simply run the cell below after changing the variables to upload and create an input table along with creating an empty output table in your project.\n",
    "\n",
    "Please note that the input table must be formated with two columns: `row` (integers) and `prompt_and_text` (strings). See `example.csv` for reference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.df import CSV_to_BigQuery\n",
    "\n",
    "#TODO Change the below variables before running this cell\n",
    "input_CSV_path = \"example.csv\"\n",
    "project_id = \"sampleproject-440900\"\n",
    "dataset_id = \"test\"\n",
    "input_table_id = \"input\"\n",
    "output_table_id = \"output\"\n",
    "\n",
    "CSV_to_BigQuery(input_CSV_path, project_id, dataset_id, input_table_id, output_table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Submit Job**\n",
    "\n",
    "Fill in the relevant information below and then run the cell to submit a job.\n",
    "\n",
    "Note:\n",
    "- Currently supported model: \"gpt-3.5-turbo\"\n",
    "- Leaving API_key empty (\"\") will result in \"sample_response\" being returned for all input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO Change the below variables before running this cell\n",
    "user_data = {\n",
    "    \"username\": \"test_user\",\n",
    "    \"password\": \"test_password\",\n",
    "    \"Client_ID\": \"test\",\n",
    "    \"User_Project_ID\": \"sampleproject-440900\",\n",
    "    \"User_Dataset_ID\": \"test\",\n",
    "    \"Input_Table_ID\": \"input\",\n",
    "    \"Output_Table_ID\": \"output\",\n",
    "    \"Model\": \"gpt-3.5-turbo\",\n",
    "    \"API_key\": \"\"  \n",
    "}\n",
    "\n",
    "import logging\n",
    "import json\n",
    "from helpers.jobPrep import retrieve_api_key, get_job_data, submit_job\n",
    "from helpers.jobStatus import wait_for_completion\n",
    "\n",
    "# Step 1: Retrieve API Key\n",
    "logging.info(\"üîë Retrieving API key...\")\n",
    "api_key = retrieve_api_key(user_data)\n",
    "\n",
    "# Step 2: Prepare and Submit Job\n",
    "if api_key:\n",
    "    logging.info(\"üìã Preparing job data...\")\n",
    "    job_data = get_job_data(user_data)\n",
    "    logging.info(\"üì§ Submitting job...\")\n",
    "    job_id = submit_job(api_key, job_data)\n",
    "\n",
    "    # Step 3: Monitor Job Status\n",
    "    if job_id:\n",
    "        logging.info(\"‚è≥ Monitoring job status...\")\n",
    "        final_status = wait_for_completion(job_id, user_data[\"Client_ID\"], api_key,3)\n",
    "        if final_status:\n",
    "            logging.info(\"üìä Final Job Status Retrieved:\")\n",
    "            logging.info(json.dumps(final_status, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Manually Check Job Status by Running Cell Below**\n",
    "\n",
    "If you would like to check on your job status please run the cell below to do so. Note that this can only be run after the previous cell has been run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.jobStatus import check_job_status\n",
    "\n",
    "check_job_status(job_id=job_id, client_id=user_data[\"Client_ID\"], api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save Output BigQuery Table as a CSV**\n",
    "\n",
    "If you prefer to have the output responses and corresponding rows saved in your local machine as a CSV rather than checking the BigQuery table in your project, run the cell below to access the output table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.df import BigQuery_to_CSV\n",
    "\n",
    "#TODO Change the below variables before running this cell\n",
    "project_id = \"sampleproject-440900\"\n",
    "dataset_id = \"test\"\n",
    "output_table_id = \"output\"\n",
    "output_csv_path = \"output.csv\"\n",
    "\n",
    "BigQuery_to_CSV(project_id, dataset_id, output_table_id, output_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
